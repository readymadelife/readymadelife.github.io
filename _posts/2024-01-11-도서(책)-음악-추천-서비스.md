---
layout: post
title: "portfolio"
subTitle: "도서(책)-음악 추천 서비스"
categories: [portfolio]
duration: "'22.05~'22.06"
---

&ensp;&ensp;미디어 환경의 변화로 인해 웹 콘텐츠 시장이 지속적으로 성장하고 있다. 성장에 따라 콘텐츠 공급이 지속적으로 확대되고 있기 때문에 차별성과 다양성을 갖춘 콘텐츠 IP를 확보할 필요가 있다. <한국콘텐츠진흥원, 2020 웹소설 이용자 실태조사>에 따르면 유료 결제하는 컨텐츠 1위는 웹소설(45.8%), 2위는 음악(35.8%)이다. 하지만 해당 콘텐츠들은 이미 시장에서 검증된 콘텐츠이기 때문에 규모가 크고 시장 점유가 이미 이루어져 있어 단독 콘텐츠로서 활용하기 어렵다. 앞서 강조했던 차별성과 다양성에 중점을 두기 위해 기존 시장에 많이 있었던 단독 플랫폼 서비스가 아닌 웹소설과 음악을 융합한 멀티 플랫폼 서비스인 ‘도서에 음악을 더하다’를 만들었다.

# 프로젝트 명

도서에 음악을 더하다

# 홈페이지 주소

없음 (네이버 부스트캠프 AI Tech 프로젝트)

# 프로젝트 기간

'22.05~'22.06

# 프로젝트 인원

4명

# 역할

프론트엔드 (streamlit), 검색엔진 구축 (elastic search), 데이터 크롤링 (도서), 키워드 기반 임베딩 벡터 제작

# 목표

임베딩 벡터를 이용한 유사도 계산을 통해 도서별 추천 플레이리스트 생성  
도서 검색 기능 및 음악 감상 기능을 이용할 수 있는 데모 페이지 제작

# 사용기술

프레임워크: 프론트엔드 (streamlit), 백엔드 (fastapi), ai 모델 학습 (pytorch)  
검색엔진: elastic search

# 모델링

모델을 4가지를 만들어 종합하여 플레이리스트를 만든다.  
모델의 종류는 총 4개로 아래와 같다.

## 키워드 기반 임베딩 벡터

도서, 음악 데이터 중 기존 키워드 활용 및 키워드 데이터 증강을 위해 키워드 기반 임베딩 벡터를 제작했다. 키워드 기반 임베딩 벡터의 핵심은 각 아이템의 sentence 데이터에서 주요 키워드를 추출한 후 기존 키워드와 합쳐 각 아이템에 대한 키워드 집합을 생성하는 것에 있다. 키워드 기반 임베딩 벡터 생성하는 프로세스는 아래 그림과 같다.
![keyword-model](</assets/img/post/2024-01-11-도서(책)-음악-추천-서비스-키워드.png>){:class='blog-img' }

1. Tokenizer: 도서 데이터에선 책 소개, 목차를, 음악 데이터에선 가사를 KoELECTRA 모듈을 사용하여 각 단어로 분리한 후, 명사 단어만 추출한다.
2. keyBERT: keyBERT 모듈을 사용해서 각 아이템에서 가장 중요한 단어를 추출한다 (5개). keyBERT 모듈은 문서에서 키워드를 추출하는 BERT기반 모듈로 TF-IDF와 다르게 별다른 전처리 과정 필요없이 좋은 성능을 보여, 현 프로젝트 기한을 고려하여 해당 모듈을 사용했다.
3. 신규 태그 + 기존 태그: 신규 태그와 기존 태그를 합쳐 각 아이템을 설명하는 키워드 집합을 생성한다.
4. Skip-Gram: 아이템의 임베딩 벡터를 생성하기 전, 각 키워드의 임베딩 벡터를 생성하기 위해 Word2Vec 중 Skip-Gram 모델을 사용해 키워드의 임베딩 벡터를 생성한다.
5. Average Word Embedding: 아이템의 임베딩 벡터를 생성하기 위해서 Skip-Gram에서 생성한 키워드 임베딩 벡터 평균을 내어 아이템의 임베딩 벡터를 생성한다. 마지막으로 도서 1권의 임베딩 벡터와 음악 전체의 임베딩 벡터의 Cosine Similarity를 계산하여 상위 15개의 음악을 선정한다.

## 감정 기반 임베딩 벡터

노래 가사와 책에는 ‘기쁨/슬픔/분노/공포/혐오’와 같이 단순한 감정만 드러나는 것이 아니라 작사가와 작가의 의도에 따라 수많은 감정들이 텍스트를 통해 표출된다. 가사와 책 본문 텍스트에서 다양한 감정 정보를 얻어 오기 위해서는 감정을 좀 더 다양하게 분류할 수 있는 모델이 필요했다. 감정 기반 임베딩 벡터를 만들기 위해 사용한 모델은 KOTE 모델로 43개의 감정에 대해 레이블이 지정된 50,000개의 한국어 온라인 댓글을 학습에 활용하였으며 다양한 감정에 대해 많은 사전 학습이 이미 이루어져 있기 때문에 가사에 속하는 다양한 감정 분류가 가능할 것이라고 판단됐다. 이미 많은 감정이 레이블링 되어있지만 여기서 한 층 더 나아가 조합 방식을 활용하여 43개의 감정을 3개씩 뽑음으로써 총 79464개의 감정을 만들었고 이를 통해 노래 가사와 책 내용에 대해 79464개의 감정 레이블을 지정하였다.  
다음으로 사용한 모델은 koBERT 모델로 가사와 책의 경우 단순하고 짧은 문장이 아니기 때문에 글을 양방향으로 보는 koBERT 모델을 사용해야했다. KOTE로 감정을 분류한 후 koBERT로 임베 딩 벡터를 만드는 전체적인 과정과 추천 방식은 다음과 같다.  
노래 가사와 책 내용 (책속으로)을 KOTE 모델의 입력으로 넣어 노래 가사와 책 내용에 대해서 분류된 감정과 가사/책 내용을 결과로 가져와서 koBERT모델의 입력 형식에 맞게 변경하고 SentencePeice 토크나이저를 통해 각 문장 을 토큰으로 분리하였으며, 패딩 과정을 거쳐 모든 문장의 길이를 통일시켰다. 그리고 마지막으로 학습 속도를 높이기 위해 attention 과정을 진행하였다. 그 후 각 토큰을 인덱스로 변환하는 과정을 거치고 koBERT 모델을 통과시킨 후 임베딩 벡터를 구하여 평균을 내고 cosine similarity를 통해 유사도가 높은 음악을 추천해주는 방식을 따랐다.

## 내용 기반 임베딩 벡터 1

KLUE-NLI dataset과 KorSTS dataset로 학습된 사전 학습 모델인 KR-SBERT 를 이용해 768 차원의 도서/음악 문장 임베딩 벡터를 생성한다.  
이후 1개의 도서 임베딩 벡터와 모든 음악 임베딩 벡터들 사이의 Cosine similarity 를 계산하고 그 값이 높은 순서대로 1개의 도서에 대해 n개의 음악을 추천한다.
![content-model-1](</assets/img/post/2024-01-11-도서(책)-음악-추천-서비스-내용1.png>){:class='blog-img' }

## 내용 기반 임베딩 벡터 2

뉴스의 댓글∙대댓글의 데이터로 학습된 KcELECTRA를 이용하여 각 도서와 음악마다 고유한 768차원의 임베딩 벡터를 생성한다. 생성된 임베딩 벡터들을 cosine similarity를 이용하여 유사도를 구하고 이를 이용해 음악 플레이리스트를 제작한다.
![content-model-2](</assets/img/post/2024-01-11-도서(책)-음악-추천-서비스-내용2.png>){:class='blog-img' }

# 서비스 아키텍처

![architecture](</assets/img/post/2024-01-11-도서(책)-음악-추천-서비스-architecture.png>){:class='blog-img' }

# 프로젝트 결과

이 프로젝트는 데모 버전밖에 만들지 않아 배포를 진행하지 않았다. 따라서 이 프로젝트에서 도서에 추천해준 음악이 잘 어울리는지는 사용자들의 피드백을 받지 못한 한계를 가진다. 또한 실시간 inference로 진행하지 않아 실시간으로 등록되는 글이나 음악에 대해서 배제된다는 점이 또한 아쉬움을 가진다.
